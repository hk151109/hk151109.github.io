Paper Title,Authors,Year,Methodology,Performance,Dataset,Key Contribution,Relevance to Our Work
ViT-DualAtt: An efficient pornographic image classification method based on Vision Transformer with dual attention,Cai et al.,2024,CNN-Transformer hierarchical structure with dual attention mechanisms,"97.2% Â± 0.1% accuracy, 1.6% miss rate",nsfw_data_scrapper (GitHub),Hierarchical CNN-Transformer combining local and global features,HIGH - Combines CNN and ViT approaches we plan to explore
Multi frame obscene video detection with ViT: an effective for detecting inappropriate content,Zhu et al.,2024,Multi-frame ViT for video analysis with temporal information,96.2% accuracy on NPDI dataset,NPDI dataset,First multi-frame ViT approach for video obscene detection,HIGH - Video analysis extension of our image classification work
Fine-Tuned Vision Transformer (ViT) for NSFW Image Classification,Falconsai,2023,Transfer learning with ViT-base-patch16-224-in21k,"98.04% accuracy, 99.48% AUC score","80,000 diverse images",High-performance ViT model with excellent generalization,HIGH - Direct ViT implementation for NSFW detection
Transfer Detection of YOLO to Focus CNN's attention on nude regions for adult content detection,Various,2021,YOLO object detection + CNN + SVM pipeline,"87.75% accuracy, 90.03% F1-score",Custom MMU dataset,Using YOLO to focus CNN attention on relevant body regions,HIGH - Object detection approach we plan to implement
On-Device Content Moderation,Samsung R&D,2021,Ensemble of object detector and classifier,"F1: 0.91, Precision: 95%, Recall: 88%","NSFW16k, NPDI dataset",Real-time on-device NSFW detection with low false positive rate,MEDIUM - Ensemble approach combining detection and classification
A Novel Pornographic Visual Content Classifier based on Sensitive Object Detection,Vietnamese Team,2021,YOLOv3 sexual object detection + NaiveBayes text classifier,"94.88% accuracy (YOLO), 93.87% (overall)",NPDI-800 dataset,Web extension for real-time pornographic website blocking,HIGH - YOLO-based object detection for sensitive content
Obscene image detection using transfer learning and feature fusion,Various,2023,Transfer learning with MobileNet V2 + DenseNet169 feature fusion,"98.50% accuracy, 98.46% sensitivity, 98.49% F1-score","NPDI, Pornography 2k, GGOI",Feature fusion of multiple pre-trained models for enhanced performance,HIGH - Transfer learning comparison across multiple architectures
Comparative analysis of vision transformers and convolutional neural networks,Murphy et al.,2022,Comparative study of ViT vs CNN architectures,ViT outperformed CNN in most cases,Medical imaging datasets,Comprehensive comparison showing ViT advantages in medical imaging,MEDIUM - General ViT vs CNN comparison study
Sensitive Image Classification by Vision Transformers,Various,2021,Vision Transformer for sensitive content classification,Superior performance compared to CNN baselines,Custom datasets from Reddit/Google,Demonstrates ViT superiority over traditional CNN approaches,HIGH - ViT application to sensitive content classification
Auditing Image-based NSFW Classifiers for Content Filtering,Leu et al.,2024,Audit study of three NSFW classifiers with bias analysis,Analysis of bias and demographic factors,"GCC, MSCOCO with demographic annotations",Identifies demographic bias in existing NSFW detection systems,MEDIUM - Bias analysis for ethical AI development
